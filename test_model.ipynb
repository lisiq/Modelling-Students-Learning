{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, Linear\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "parameters = {\n",
    "    \"hidden_dims\": [16,8,8],\n",
    "    \"df_name\": 'mindsteps_set_full',\n",
    "    \"epochs\": 10000,\n",
    "    \"learning_rate\": 0.005,\n",
    "    'weight_decay': 0,\n",
    "    'dropout': 0.4,\n",
    "    'early_stopping': 200,\n",
    "    'n_splits': 10,\n",
    "    'device': 'cuda',\n",
    "    'batch_size': 1024\n",
    "}\n",
    "    \n",
    "\n",
    "df = load_data_heterogeneous(parameters[\"df_name\"])\n",
    "data = create_data_object_heterogeneous(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: insufficient resources when calling `cusparseSpGEMM_workEstimation( handle, opA, opB, &alpha, matA, matB, &beta, matC, computeType, CUSPARSE_SPGEMM_DEFAULT, spgemmDesc, &bufferSize1, dBuffer1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\liq02qc\\Desktop\\GitHub\\Modelling-Students-Learning\\new_model.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Generate the co-occurence matrix of movies<>movies:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m metapath \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrev_takes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstudent\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mstudent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtakes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_data \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39;49mAddMetaPaths(metapaths\u001b[39m=\u001b[39;49m[metapath])(train_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Apply normalization to filter the metapath:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m _, edge_weight \u001b[39m=\u001b[39m gcn_norm(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     train_data[\u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39medge_index,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     num_nodes\u001b[39m=\u001b[39mtrain_data[\u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mnum_nodes,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     add_self_loops\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/liq02qc/Desktop/GitHub/Modelling-Students-Learning/new_model.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\liq02qc\\AppData\\Local\\anaconda3\\envs\\stud_net\\lib\\site-packages\\torch_geometric\\transforms\\add_metapaths.py:156\u001b[0m, in \u001b[0;36mAddMetaPaths.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    151\u001b[0m edge_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_edge_weight(data, edge_type)\n\u001b[0;32m    152\u001b[0m adj2 \u001b[39m=\u001b[39m SparseTensor\u001b[39m.\u001b[39mfrom_edge_index(\n\u001b[0;32m    153\u001b[0m     edge_index\u001b[39m=\u001b[39mdata[edge_type]\u001b[39m.\u001b[39medge_index,\n\u001b[0;32m    154\u001b[0m     sparse_sizes\u001b[39m=\u001b[39mdata[edge_type]\u001b[39m.\u001b[39msize(), edge_attr\u001b[39m=\u001b[39medge_weight)\n\u001b[1;32m--> 156\u001b[0m adj1 \u001b[39m=\u001b[39m adj1 \u001b[39m@\u001b[39;49m adj2\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     adj1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_adj(adj1)\n",
      "File \u001b[1;32mc:\\Users\\liq02qc\\AppData\\Local\\anaconda3\\envs\\stud_net\\lib\\site-packages\\torch_sparse\\matmul.py:171\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    167\u001b[0m SparseTensor\u001b[39m.\u001b[39mspspmm \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m, other, reduce\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m: spspmm(\n\u001b[0;32m    168\u001b[0m     \u001b[39mself\u001b[39m, other, reduce)\n\u001b[0;32m    169\u001b[0m SparseTensor\u001b[39m.\u001b[39mmatmul \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m, other, reduce\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m: matmul(\n\u001b[0;32m    170\u001b[0m     \u001b[39mself\u001b[39m, other, reduce)\n\u001b[1;32m--> 171\u001b[0m SparseTensor\u001b[39m.\u001b[39m\u001b[39m__matmul__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m, other: matmul(\u001b[39mself\u001b[39;49m, other, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\liq02qc\\AppData\\Local\\anaconda3\\envs\\stud_net\\lib\\site-packages\\torch_sparse\\matmul.py:162\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(src, other, reduce)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m spmm(src, other, reduce)\n\u001b[0;32m    161\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, SparseTensor):\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m spspmm(src, other, reduce)\n\u001b[0;32m    163\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liq02qc\\AppData\\Local\\anaconda3\\envs\\stud_net\\lib\\site-packages\\torch_sparse\\matmul.py:122\u001b[0m, in \u001b[0;36mspspmm\u001b[1;34m(src, other, reduce)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspspmm\u001b[39m(src: SparseTensor,\n\u001b[0;32m    119\u001b[0m            other: SparseTensor,\n\u001b[0;32m    120\u001b[0m            reduce: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SparseTensor:\n\u001b[0;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 122\u001b[0m         \u001b[39mreturn\u001b[39;00m spspmm_sum(src, other)\n\u001b[0;32m    123\u001b[0m     \u001b[39melif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    124\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liq02qc\\AppData\\Local\\anaconda3\\envs\\stud_net\\lib\\site-packages\\torch_sparse\\matmul.py:97\u001b[0m, in \u001b[0;36mspspmm_sum\u001b[1;34m(src, other)\u001b[0m\n\u001b[0;32m     95\u001b[0m A \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mto_torch_sparse_coo_tensor()\n\u001b[0;32m     96\u001b[0m B \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mto_torch_sparse_coo_tensor()\n\u001b[1;32m---> 97\u001b[0m C \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mmm(A, B)\n\u001b[0;32m     98\u001b[0m edge_index \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39m_indices()\n\u001b[0;32m     99\u001b[0m row, col \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39m], edge_index[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: insufficient resources when calling `cusparseSpGEMM_workEstimation( handle, opA, opB, &alpha, matA, matB, &beta, matC, computeType, CUSPARSE_SPGEMM_DEFAULT, spgemmDesc, &bufferSize1, dBuffer1)`"
     ]
    }
   ],
   "source": [
    "# Perform a link-level split into training, validation, and test edges:\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('student', 'takes', 'code')],\n",
    "    rev_edge_types=[('code', 'rev_takes', 'student')],\n",
    ")(data)\n",
    "\n",
    "# Generate the co-occurence matrix of movies<>movies:\n",
    "metapath = [('code', 'rev_takes', 'student'), ('student', 'takes', 'code')]\n",
    "train_data = T.AddMetaPaths(metapaths=[metapath])(train_data)\n",
    "\n",
    "# Apply normalization to filter the metapath:\n",
    "_, edge_weight = gcn_norm(\n",
    "    train_data['code', 'code'].edge_index,\n",
    "    num_nodes=train_data['code'].num_nodes,\n",
    "    add_self_loops=False,\n",
    ")\n",
    "edge_index = train_data['code', 'code'].edge_index[:, edge_weight > 0.002]\n",
    "\n",
    "train_data['code', 'metapath_0', 'code'].edge_index = edge_index\n",
    "val_data['code', 'metapath_0', 'code'].edge_index = edge_index\n",
    "test_data['code', 'metapath_0', 'code'].edge_index = edge_index\n",
    "\n",
    "\n",
    "class MovieGNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(-1, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "class UserGNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv3 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        movie_x = self.conv1(\n",
    "            x_dict['code'],\n",
    "            edge_index_dict[('code', 'metapath_0', 'code')],\n",
    "        ).relu()\n",
    "\n",
    "        user_x = self.conv2(\n",
    "            (x_dict['code'], x_dict['student']),\n",
    "            edge_index_dict[('code', 'rev_takes', 'student')],\n",
    "        ).relu()\n",
    "\n",
    "        user_x = self.conv3(\n",
    "            (movie_x, user_x),\n",
    "            edge_index_dict[('code', 'rev_takes', 'student')],\n",
    "        ).relu()\n",
    "\n",
    "        return self.lin(user_x)\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_src[row], z_dst[col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_users, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.user_emb = Embedding(num_users, hidden_channels)\n",
    "        self.user_encoder = UserGNNEncoder(hidden_channels, out_channels)\n",
    "        self.movie_encoder = MovieGNNEncoder(hidden_channels, out_channels)\n",
    "        self.decoder = EdgeDecoder(out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = {}\n",
    "        x_dict['student'] = self.user_emb(x_dict['student'])\n",
    "        z_dict['student'] = self.user_encoder(x_dict, edge_index_dict)\n",
    "        z_dict['code'] = self.movie_encoder(\n",
    "            x_dict['code'],\n",
    "            edge_index_dict[('code', 'metapath_0', 'code')],\n",
    "        )\n",
    "        return self.decoder(z_dict['student'], z_dict['code'], edge_label_index)\n",
    "\n",
    "\n",
    "model = Model(data['student'].num_nodes, hidden_channels=64, out_channels=64)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(\n",
    "        train_data.x_dict,\n",
    "        train_data.edge_index_dict,\n",
    "        train_data['student', 'code'].edge_label_index,\n",
    "    )\n",
    "    loss = F.mse_loss(out, train_data['student', 'code'].edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(\n",
    "        data.x_dict,\n",
    "        data.edge_index_dict,\n",
    "        data['student', 'code'].edge_label_index,\n",
    "    ).clamp(min=0, max=5)\n",
    "    rmse = F.mse_loss(out, data['student', 'code'].edge_label).sqrt()\n",
    "    return float(rmse)\n",
    "\n",
    "\n",
    "for epoch in range(1, 701):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:04d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
