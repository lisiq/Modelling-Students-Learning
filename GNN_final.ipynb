{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "IRT_DIMS = 1\n",
    "DATASET = 'full'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, shutil\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from utils import (mymode, load_data_heterogeneous, create_data_object_heterogeneous)\n",
    "import seaborn as sns\n",
    "\n",
    "from IRT import MIRT_2PL\n",
    "from Heterogeneous_embedder import EmbedderHeterogeneous, train_embedder_heterogeneous, test_embedder_heterogeneous\n",
    "from manage_experiments import perform_cross_validation\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1162775489.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    'neighbours': [50, 50]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Initialise\n",
    "parameters = {\n",
    "    'df_name': None,\n",
    "    'epochs': 10000,\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 0,\n",
    "    'early_stopping': 200,\n",
    "    'n_splits': 10,\n",
    "    'device': 'cuda:0',\n",
    "    'batch_size': 2**13,\n",
    "    'neighbours': [50, 50]\n",
    "    }\n",
    "\n",
    "if IRT_DIMS > 0:\n",
    "    parameters['model_type'] = 'IRT'\n",
    "    parameters['hidden_dims'] = IRT_DIMS\n",
    "    parameters['lambda1'] = 0\n",
    "    parameters['lambda2'] = 0\n",
    "    OUTNAME = 'IRT'\n",
    "else:\n",
    "    parameters['model_type'] = 'GNN'\n",
    "    parameters['hidden_dims'] = [16,8]\n",
    "    OUTNAME = 'SAGE' \n",
    "    \n",
    "print(parameters)\n",
    "print(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'data/mindsteps_set_' + DATASET\n",
    "df = load_data_heterogeneous(DATA_FILE)\n",
    "data, df_student, df_item, df_edge = create_data_object_heterogeneous(df, return_aux_data=True, item_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_dim = data['student', 'responds', 'item'].edge_attr.shape[1]\n",
    "if IRT_DIMS > 0:\n",
    "    model = MIRT_2PL(IRT_DIMS, edge_dim, data)\n",
    "else:\n",
    "    model = EmbedderHeterogeneous( \n",
    "        n_students =  data['student'].x.size(0),\n",
    "        n_items = data['item'].x.size(0),\n",
    "        student_inchannel = data['student'].x.size(1),\n",
    "        item_inchannel = data['item'].x.size(1),\n",
    "        hidden_channels=parameters['hidden_dims'],\n",
    "        edge_channel=edge_dim,\n",
    "        metadata=data.metadata()\n",
    "        ).to(device)\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict, model = perform_cross_validation(data, parameters, save_embeddings=True, save_subgraph=True, final_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict.keys()\n",
    "print('AUC:', output_dict['AUC_0_test'])\n",
    "print('Balanced Accuracy:', output_dict['Balanced Accuracy_0_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_scales = df_item['scale'].unique()\n",
    "unique_domains = df_item['domain'].unique()\n",
    "unique_matdiff = df_item['matdiff'].sort_values().unique()\n",
    "#scale_colors = dict([(c, plt.cm.tab10(i)) for i, c in enumerate(unique_scales)])\n",
    "#domain_colors = dict([(c, plt.cm.tab10(i)) for i, c in enumerate(unique_domains)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = output_dict['losses_0']\n",
    "train_edge_indices, val_edge_indices, test_edge_indices = output_dict['indices_0']\n",
    "\n",
    "train_data = output_dict['train_subgraph_data'] \n",
    "val_data = output_dict['val_subgraph_data'] \n",
    "test_data = output_dict['test_subgraph_data']\n",
    "\n",
    "aux_data = (df, df_student, df_item, df_edge, \n",
    "    #clustering_indices, \n",
    "    train_losses, #test_losses, test_aucs, \n",
    "    train_edge_indices, val_edge_indices, test_edge_indices, \n",
    "    data.cpu(), train_data.cpu(), val_data.cpu(), test_data.cpu(),\n",
    "    unique_scales, unique_domains, unique_matdiff, \n",
    "    DATA_FILE)\n",
    "\n",
    "with open(f'./results/{OUTNAME}_{DATASET}_aux_data.pkl', 'wb') as handle:\n",
    "    pickle.dump(aux_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE EVERYTHING\n",
    "torch.save(model, f'./results/{OUTNAME}_{DATASET}.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.arange(len(train_losses))\n",
    "fig = plt.figure()\n",
    "plt.plot(train_indices, train_losses, c='blue')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save IRT parameters to matrix\n",
    "if OUTNAME == 'IRT' and IRT_DIMS == 1:    \n",
    "    #z_dict = model.get_embeddings(train_data.to(device))\n",
    "    z_dict = output_dict['embedding_0']\n",
    "    df_item['IRT1_difficulty'] = -z_dict['item']\n",
    "    df_item['IRT1_discrimination'] = z_dict['offset']\n",
    "    ability = z_dict['ability']\n",
    "    df_edge['IRT1_ability'] = ability.ravel()\n",
    "    \n",
    "    aux_data = (df, df_student, df_item, df_edge, \n",
    "    train_losses, \n",
    "    train_edge_indices, val_edge_indices, test_edge_indices,\n",
    "    data.cpu(), train_data.cpu(), val_data.cpu().cpu(), test_data.cpu(),\n",
    "    unique_scales, unique_domains, unique_matdiff, \n",
    "    DATA_FILE)\n",
    "\n",
    "    with open(f'./results/{OUTNAME}_{DATASET}_aux_data_IRT1.pkl', 'wb') as handle:\n",
    "        pickle.dump(aux_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    df_item_clean = df_item.dropna(subset=['IRT_difficulty', 'IRT1_difficulty'])    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    sns.scatterplot(x='IRT_difficulty', y='IRT1_difficulty', data=df_item, hue='scale')\n",
    "    plt.title('Difficulty')\n",
    "    print('Difficulty:', pearsonr(df_item_clean['IRT1_difficulty'], df_item_clean['IRT_difficulty']))\n",
    "    \n",
    "    edge_feat = train_data['student', 'responds', 'item'].edge_attr.detach().cpu().numpy()\n",
    "    df_edge_clean = df_edge.dropna(subset=['IRT1_ability', 'ability', 'age'])\n",
    "    fig = plt.figure()\n",
    "    sns.scatterplot(x='age', y='IRT1_ability', data=df_edge_clean, hue='grade')\n",
    "    plt.title('Age-Ability')\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    sns.scatterplot(x='grade', y='IRT1_ability', data=df_edge_clean, hue='age')\n",
    "    plt.title('Grade-Ability')\n",
    "    print('Age-Ability:', pearsonr(df_edge_clean['age'], df_edge_clean['IRT1_ability']))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    sns.scatterplot(x='ability', y='IRT1_ability', data=df_edge_clean, hue='grade')\n",
    "    plt.title('Ability')\n",
    "    print('Ability:', pearsonr(df_edge_clean['ability'], df_edge_clean['IRT1_ability']))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "88516cc94b965045253aac22be7e673e07faa374a8dfeab45aefc65ddf94d8b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
